## 第二部分

# 第八章 当模型遇到数据

本书的第一部分介绍了构成许多机器学习方法基础的数学知识。希望读者能够从第一部分学习到数学语言的基础形式，我们现在将用这些知识来描述和讨论机器学习。本书的第二部分介绍了机器学习的四大支柱：

回归（第9章）  
降维（第10章）  
密度估计（第11章）  
分类（第12章）

本书这一部分的主要目的是说明如何利用第一部分介绍的数学概念来设计机器学习算法，这些算法可以用于解决属于这四个支柱范围内的任务。我们并不打算引入高级的机器学习概念，而是提供一套实用的方法，使读者能够运用他们在本书第一部分中获得的知识。它也为已经熟悉数学的读者提供了通向更广泛的机器学习文献的大门。

## 8.1 数据、模型和学习

现在值得暂停一下，思考一下机器学习算法旨在解决的问题。正如第一章所讨论的，机器学习系统有三个主要组成部分：数据、模型和学习。机器学习的主要问题是“我们所说的好的模型是什么意思？”这个词“模型”有很多细微之处，我们将在本章多次回顾它。如何客观地定义“好”这个词也并非完全显而易见。机器学习的一个指导原则是，好的模型应该在未见过的数据上表现良好。这就要求我们定义一些性能指标，例如准确性或与真实值的距离，以及找出如何在这种性能指标下表现良好的方法。本章涵盖了一些常用的数学和统计语言片段，这些语言片段常用于讨论机器学习模型。通过这样做，我们简要概述了当前的最佳实践，即训练模型使得生成的预测器在我们尚未见过的数据上表现出色。

正如第一章所述，我们在两种不同的意义上使用“机器学习算法”这一短语：训练和预测。本章我们将描述这些概念，以及在不同模型之间进行选择的想法。我们将在第8.2节介绍经验风险最小化框架，在第8.3节介绍最大似然原理，在第8.4节介绍概率模型的概念。在第8.5节中，我们简要概述了一种图形语言，用于指定概率模型，并在第8.6节中讨论模型选择。本节其余部分将扩展机器学习的三大主要组成部分：数据、模型和学习。

![](images/dd57699e06664954ce4ea38719c543e304388d32d35a2789b04a7dcee5e1369e.jpg)

### 8.1.1 数据作为向量

我们假设数据处于整洁的格式（Wickham, 2014; Codd, 1990）。我们假定数据可以被计算机读取，并且可以用数值格式适当地表示。数据被认为是表格化的（图8.1），我们把表中的每一行看作代表一个特定的实例或样本，每一列代表一个特定的特征。近年来，机器学习已被应用于许多明显不是表格数值格式的数据类型，例如基因序列、网页上的文本和图像内容，以及社交媒体图谱。我们不讨论识别良好特征的重要和具有挑战性的方面。许多这些方面依赖于领域专业知识，并需要仔细的工程设计，近年来它们被纳入了数据科学的范畴（Stray, 2016; Adhikari 和 DeNero, 2018）。

即使我们已经有表格格式的数据，仍然需要做出选择以获得数值表示。例如，在表8.1中，性别列（一个类别变量）可以转换为数字0代表“男性”，1代表“女性”。或者，性别可以用-1和+1分别表示（如表8.2所示）。此外，在构造表示时，经常需要使用领域知识，例如知道大学学位从学士到硕士再到博士学位逐步递进，或者意识到提供的邮政编码不仅是一串字符，实际上编码了一个伦敦区域。在表8.2中，我们将表8.1中的数据转换为数值格式，每个邮政编码表示为两个数字，分别是纬度和经度。即使是潜在可以直接输入机器学习算法的数值数据，也应该仔细考虑单位、缩放和约束。如果没有额外的信息，我们应该平移和缩放数据集的所有列，使其经验均值为0，经验方差为1。为了本书的目的，我们假设领域专家已经适当地转换了数据，即每个输入${\pmb x}_{n}$是一个$D$维实数向量，这些被称为特征、属性或协变量。我们认为数据集的形式如表8.2所示。请注意，我们在新的数值表示中去掉了表8.1中的Name列。这样做的主要原因有两个：（1）我们不期望标识符（即姓名）对机器学习任务有信息价值；（2）我们可能希望匿名化数据以帮助保护员工的隐私。

**特征**、**属性**、**协变量**

在本书的这部分中，我们将用$N$表示数据集中样本的数量，并用小写的$n=1,\ldots,N$来索引这些样本。我们假设我们有一组数值数据，表示为向量数组（表8.2）。每一行代表一个特定的个体${\pmb x}_{n}$，通常在机器学习中称为“示例”或“数据点”。下标$n$表示这是数据集中$N$个示例中的第$n$个示例。每一列表示关于示例的特定感兴趣的特征，我们用$d=1,\cdots,D$来索引这些特征。回想一下，数据表示为向量，这意味着每个示例（每个数据点）都是$D$维向量。表格的方向源自数据库社区，但对于某些机器学习算法（例如第10章），将示例表示为列向量更为方便。

让我们考虑基于表8.2中的数据预测年收入的问题。这是一个监督学习问题，每个示例${\bf x}_{n}$（年龄）都有一个标签$y_{n}$（薪水）。标签$y_{n}$还有其他名称，包括目标、响应变量和注解。数据集写成示例-标签对的集合$\{({\pmb x}_{1}, y_{1}), \cdots, ({\pmb x}_{n}, y_{n}), \cdots, ({\pmb x}_{N}, y_{N})\}$。示例$\{{\pmb x}_{1}, \cdots, {\pmb x}_{N}\}$通常会连接在一起，并写作$\boldsymbol{X} \in \mathbb{R}^{N \times D}$。图8.1展示了由表8.2中右侧两列组成的训练数据集，其中$x=\text{age}$，$y=$薪水。 

我们使用本书第一部分介绍的概念来形式化

![](images/e3f1a12c34526643db50fd95355c25536727392eb9147c1d2f3037df59088db7.jpg)

图8.1 用于线性回归的玩具数据。来自表8.2右端两列的训练数据$(x_{n}, y_{n})$。我们感兴趣的是一个60岁的人（$x=60$）的薪水，如图中垂直虚线所示，这不属于训练数据的一部分。

机器学习问题，如前一段所述。将数据表示为向量${\pmb x}_{n}$允许我们使用线性代数（在第2章介绍）中的概念。在许多机器学习算法中，我们还需要能够比较两个向量。正如我们在第9章和第12章中看到的，计算两个示例之间的相似度或距离允许我们形式化这样的直觉：具有相似特征的示例应该具有相似的标签。比较两个向量需要我们构建几何结构（在第3章中解释），并允许我们使用第7章的技术优化由此产生的学习问题。

**特征映射**、**核**

由于我们已经有了数据的向量表示，我们可以操作数据以找到可能更好的表示。我们将以两种方式讨论寻找良好的表示：找到原始特征向量的低维近似，以及使用原始特征向量的非线性高维组合。在第10章中，我们将看到通过找到主成分来找到原始数据空间的低维近似的一个例子。找到主成分与第4章介绍的特征值和奇异值分解的概念密切相关。对于高维表示，我们将看到一个明确的特征映射$\phi(\cdot)$，它允许我们使用高维表示$\phi({\pmb x}_{n})$来表示输入${\pmb x}_{n}$。高维表示的主要动机是我们可以构造新的特征作为原始特征的非线性组合，这反过来可能会使学习问题更容易。我们将在第9.2节讨论特征映射，并在第12.4节展示这个特征映射如何导致一个核。近年来，深度学习方法（Goodfellow 等人，2016）在使用数据本身学习新特征方面显示出潜力，并在计算机视觉、语音识别和自然语言处理等领域取得了巨大成功。我们不会在这部分书中涉及神经网络，但读者可以参考第5.6节以了解反向传播的数学描述，这是训练神经网络的关键概念。

![](images/0da30ae7147f02bb3f1ea24d111da281055c8285c52448668544bab1a5a5c356.jpg)

图8.2 示例函数（黑色实对角线）及其在$x=60$处的预测，即$f(60)=100$。
### 8.1.2 模型作为函数

一旦我们将数据表示为适当的向量，我们就可以开始构建预测函数（称为预测器）。在第 1章中，我们还没有足够的语言来精确地描述模型。利用本书第一部分的概念，我们现在可以引入“模型”的含义。本书介绍了两种主要的方法：一种是将预测器视为函数，另一种是将预测器视为概率模型。我们在这里描述前者，在下一小节中描述后者。

预测器是一个函数，当给定一个特定的输入示例（在我们的案例中是一个特征向量）时，会产生一个输出。目前，我们将输出视为一个单一的数值，即一个实数值标量。这可以表示为：

$$
f:\mathbb{R}^{D}\rightarrow\mathbb{R}\,,
$$

其中输入向量$_{\pmb{x}}$是$D$维的（有$D$个特征），函数$f$然后应用于它（写为$f(\pmb{x})$）返回一个实数。图 8.2 展示了可用于计算输入值$x$的预测值的可能函数。

在本书中，我们不考虑所有函数的一般情况，这将涉及到泛函分析的需求。相反，我们考虑线性函数的特殊情况：

$$
\pmb{f}(\pmb{x})=\pmb{\theta}^{\top}\pmb{x}+\pmb{\theta}_{0}
$$

其中未知参数为$\pmb{\theta}$和$\theta_{0}$。这种限制意味着第 2章和第 3章的内容足以精确地表述非概率（与接下来描述的概率观点相对）视角下的预测器概念。

![](images/6ada0bf97538f65c7d2fb948d6a2bd10e92cb79eb1cd476caf4a5102d2a53c8d.jpg)

图 8.3 示例函数（黑色实对角线）及其在$x=60$处的预测不确定性（绘制为高斯分布）。

线性函数在可解决的问题的广泛性和所需背景数学知识之间达到了很好的平衡。

### 8.1.3 模型作为概率分布

我们通常认为数据是某种真实底层效应的噪声观测值，并希望通过应用机器学习来从噪声中识别信号。这要求我们有一种量化噪声影响的语言。我们也希望预测器能够表达某种不确定性，例如量化我们对特定测试数据点预测值的信心。正如我们在第 6章中看到的，概率论提供了一种量化不确定性的语言。图 8.3 展示了函数预测不确定性的高斯分布。

与其将预测器视为单个函数，我们也可以将预测器视为概率模型，即描述可能函数分布的模型。在本书中，我们限于有限维参数分布的特殊情形，这使得我们能够在不需要随机过程和随机测度的情况下描述概率模型。对于这种特殊情形，我们可以将概率模型视为多元概率分布，这已经允许丰富的模型类。

我们将在第 8.4 节介绍如何使用概率论（第 6章）的概念来定义机器学习模型，并在第 8.5 节介绍一种图形语言，以紧凑的方式描述概率模型。

### 8.1.4 学习是寻找参数

学习的目标是找到一个模型及其相应的参数，使得由此产生的预测器在未见过的数据上表现良好。在讨论机器学习算法时，概念上有三个不同的算法阶段：

1. 预测或推理

2. 训练或参数估计

3. 超参数调优或模型选择

预测阶段是在以前未见过的测试数据上使用训练好的预测器。换句话说，参数和模型选择已经固定，预测器被应用于代表新输入数据点的新向量。如第 1章和前一小节所述，本书将讨论两种机器学习流派，对应于预测器是函数还是概率模型。当我们有概率模型（在第 8.4 节进一步讨论）时，预测阶段被称为推理。

备注：不幸的是，不同算法阶段的命名没有统一标准。“推理”这个词有时也用来指概率模型的参数估计，而在较少情况下也可能用于指非概率模型的预测。$\diamondsuit$

训练或参数估计阶段是我们根据训练数据调整预测模型的时候。我们希望根据训练数据找到一个好的预测器，主要有两种策略：基于某些质量指标找到最佳预测器（有时称为找到点估计），或者使用贝叶斯推断。找到点估计可以应用于两种类型的预测器，但贝叶斯推断需要概率模型。

对于非概率模型，我们遵循经验风险最小化的原则，我们在第 8.2 节中对此进行了描述。经验风险最小化直接提供了寻找好参数的优化问题。对于统计模型，最大似然原则用于找到一组好的参数（第 8.3 节）。我们还可以使用概率模型来建模参数的不确定性，这将在第 8.4 节中更详细地探讨。

我们使用数值方法来找到适合数据的好参数，大多数训练方法可以看作是爬山法，以找到目标的最大值，例如似然的最大值。为了应用爬山法，我们使用第 5章中描述的梯度并实现第 7章中的数值优化方法。

如第 1章所述，我们感兴趣的是基于数据学习一个模型，使其在未来数据上表现良好。仅仅通过经验风险最小化不足以让模型只在训练数据上拟合得很好，预测器需要在未见过的数据上表现良好。我们使用交叉验证（第 8.2.4 节）来模拟预测器在未来未见过的数据上的行为。正如本章所见，要实现对未来数据的良好表现，我们需要在训练数据上的拟合程度和发现现象的“简单”解释之间取得平衡。这种权衡是通过正则化（第 8.2.3 节）或添加先验（第 8.3.2 节）来实现的。在哲学上，这被认为既不是归纳也不是演绎，而是称为溯因。根据《斯坦福哲学百科全书》，溯因是推理到最佳解释的过程（Douven, 2017）。

我们经常需要在预测器结构的高层次上做出建模决策，例如使用的组件数量或要考虑的概率分布类别。组件数量的选择是一个超参数的例子，这个选择可能会显著影响模型的性能。在不同模型之间进行选择的问题称为模型选择，我们在第 8.6 节中描述。对于非概率模型，模型选择通常使用嵌套交叉验证来完成，这在第 8.6.1 节中描述。我们还使用模型选择来选择模型的超参数。

备注：参数和超参数之间的区别有些随意，主要是由数值优化与搜索技术的区别驱动的。另一种考虑这种区别的方法是将参数视为概率模型的显式参数，将超参数（高层级参数）视为控制这些显式参数分布的参数。$\diamondsuit$

在接下来的几节中，我们将探讨三种机器学习方法：经验风险最小化（第 8.2 节）、最大似然原则（第 8.3 节）和概率建模（第 8.4 节）。

## 8.2 经验风险最小化

在掌握了所有的数学知识之后，我们现在可以引入学习的意义了。机器学习中的“学习”部分归根结底是基于训练数据来估计参数。

在本节中，我们考虑预测器是一个函数的情况，并在第 8.3 节中讨论概率模型的情形。我们将描述经验风险最小化的概念，这一概念最初由支持向量机（在第 12 章中描述）的提出而广受欢迎。然而，其基本原则具有广泛的适用性，使我们能够在不显式构建概率模型的情况下探讨什么是学习。这里有四个主要的设计选择，我们将在下面的小节中详细讨论：

8.2.1 要允许预测器采用哪些函数集？

8.2.2 我们如何衡量预测器在训练数据上的表现？

8.2.3 如何仅从训练数据构造在未见过的测试数据上表现良好的预测器？

8.2.4 搜索模型空间的程序是什么？

### 8.2.1 函数假设类

假设我们有 $N$ 个样本 $\pmb{x}_{n}\in\mathbb{R}^{D}$ 和相应的标量标签 $y_{n}\in\mathbb{R}$，这是监督学习设置，在这种情况下，我们获得对 $(\pmb{x}_{1},y_{1}),.\,.\,.\,,(\pmb{x}_{N},y_{N})$ 的成对数据。给定这些数据，我们希望估计一个预测器 $f(\cdot,\theta):\mathbb{R}^{D}\rightarrow\mathbb{R}$，参数化为 $\pmb{\theta}$。我们希望找到一个好的参数 $\pmb{\theta}^{*}$，使得我们可以很好地拟合数据，即

$$
f(x_{n},\theta^{*})\approx y_{n}\quad\text{对于}\quad n=1,.\,.\,,N\,.
$$

在本节中，我们使用记号 $\hat{y}_{n}=f(\pmb{x}_{n},\pmb{\theta}^{*})$ 来表示预测器的输出。

备注：为了便于表述，我们将用监督学习（我们有标签）的方式来描述经验风险最小化。这简化了假设类和损失函数的定义。在机器学习中，通常会选择一个参数化的函数类，例如仿射函数。$\diamondsuit$
### 示例 8.1

我们通过普通最小二乘回归问题来介绍经验风险最小化。关于回归的更全面的讨论见第 9 章。当标签 $y_{n}$ 是实数值时，预测器的函数类的一个流行选择是仿射函数集。我们通过将额外的单位特征 $x^{(0)}=1$ 连接到 $\pmb{x}_{n}$ 来采用更紧凑的仿射函数表示，即 $\pmb{x}_{n}=[1,x_{n}^{(1)},x_{n}^{(2)},.\,.\,.\,,x_{n}^{(D)}]^{\top}$。对应的参数向量为 $\pmb{\theta}=[\theta_{0},\theta_{1},\theta_{2},.\,.\,.\,,\theta_{D}]^{\top}$，这允许我们将预测器写成线性函数

$$
f(\pmb{x}_{n},\pmb{\theta})=\pmb{\theta}^{\top}\pmb{x}_{n}\,.
$$

这个线性预测器等价于仿射模型

$$
f({\pmb x}_{n},{\pmb\theta})={\pmb\theta}_{0}+\sum_{d=1}^{D}{\theta}_{d}x_{n}^{(d)}\,.
$$

预测器以单个样本 ${\pmb x}_{n}$ 的特征向量作为输入，并产生一个实数值输出，即 $f:\mathbb{R}^{D+1}\rightarrow\mathbb{R}$。本章之前的图中使用了一条直线作为预测器，这意味着我们假设了一个仿射函数。

除了线性函数，我们可能希望考虑非线性函数作为预测器。神经网络的最新进展使得计算更复杂的非线性函数类变得高效。

给定函数类后，我们希望搜索一个好的预测器。现在我们转向经验风险最小化的第二个要素：如何衡量预测器对训练数据的拟合程度。

### 8.2.2 训练的损失函数

损失函数

“误差”一词经常用来表示损失。独立同分布

训练集

经验风险

经验风险最小化

考虑特定样本的标签 $y_{n}$，以及基于 ${\pmb x}_{n}$ 得到的相应预测 $\hat{y}_{n}$。为了定义什么是良好地拟合数据，我们需要指定一个损失函数 $\ell(y_{n},\hat{y}_{n})$，它接受真实标签和预测值作为输入，并产生一个非负数（称为损失），表示我们在该特定预测上犯了多少错误。我们寻找一个好的参数向量 $\pmb{\theta}^{*}$ 的目标是将 $N$ 个训练样本的平均损失最小化。

在机器学习中常见的一个假设是，样本集 $(\pmb{x}_{1},y_{1}),\dots,(\pmb{x}_{N},y_{N})$ 是独立同分布的。独立意味着两个数据点 $(x_{i},y_{i})$ 和 $(\pmb{x}_{j},y_{j})$ 在统计上不相互依赖，这意味着经验均值是总体均值的良好估计（第 6.4.1 节）。这意味着我们可以使用训练数据上的经验均值。对于给定的训练集 $\{({\pmb x}_{1},y_{1}),.\,.\,.\,,({\pmb x}_{N},y_{N})\}$，定义矩阵表示 $\pmb{X}\,:=\,[\pmb{x}_{1},.\,.\,.\,,\pmb{x}_{N}]^{\top}\,\in\mathbb{R}^{N\times D}$ 和标签向量 $\pmb{y}\ :=\ [y_{1},.\,.\,.\,,y_{N}]^{\top}\ \in\ \mathbb{R}^{N}$。使用这种矩阵表示，平均损失为

$$
{\bf R}_{\mathrm{emp}}(f,\pmb{X},\pmb{y})=\frac{1}{N}\sum_{n=1}^{N}\ell(y_{n},\hat{y}_{n})\,,
$$

其中 $\hat{y}_{n}=f(\pmb{x}_{n},\pmb{\theta})$。方程 (8.6) 称为经验风险，并且依赖于三个参数：预测器 $f$ 和数据 $\pmb{X},\pmb{y}$。这种学习的一般策略称为经验风险最小化。

### 示例 8.2（最小二乘损失）

继续最小二乘回归的例子，我们指定使用平方损失 $\ell(y_{n},\hat{y}_{n})=(y_{n}-\hat{y}_{n})^{2}$ 来度量训练期间出现错误的成本。我们希望最小化经验风险（8.6），这是数据上损失的平均值

$$
\operatorname*{min}_{\pmb{\theta}\in\mathbb{R}^{D}}\frac{1}{N}\sum_{n=1}^{N}(y_{n}-f(\pmb{x}_{n},\pmb{\theta}))^{2},
$$

其中我们将预测器替换为 $\hat{y}_{n}=f(\pmb{x}_{n},\pmb{\theta})$。通过使用线性预测器的选择 $\bar{f(\pmb{x}_{n},\pmb{\theta})}=\pmb{\theta}^{\top}\pmb{x}_{n}$，我们得到优化问题

$$
\operatorname*{min}_{\pmb{\theta}\in\mathbb{R}^{D}}\frac{1}{N}\sum_{n=1}^{N}(y_{n}-\pmb{\theta}^{\top}\pmb{x}_{n})^{2}\,.
$$

此方程可以用矩阵形式等价表达为

$$
\operatorname*{min}_{\pmb{\theta}\in\mathbb{R}^{D}}\frac{1}{N}\left\|\pmb{y}-\pmb{X}\pmb{\theta}\right\|^{2}\,.
$$

这被称为**最小二乘问题**。通过求解正规方程可以得到其闭式解析解，我们将在第 9.2 节中详细讨论这一点。

最小二乘问题

我们不满足于只在训练数据上表现良好的预测器。相反，我们寻求在未见过的测试数据上表现良好的预测器（具有较低的风险）。更正式地说，我们感兴趣的是找到一个预测器 $f$（参数固定），该预测器最小化**期望风险**

期望风险

$$
\mathbf{R}_{\mathrm{true}}(f)=\mathbb{E}_{\mathbf{x},y}[\ell(y,f(\mathbf{x}))]\,,
$$

其中 $y$ 是标签，$f(\pmb{x})$ 是基于样本 $\pmb{x}$ 的预测。记号 $\mathbf{R}_{\mathrm{true}}(f)$ 表明这是如果我们拥有无限数量的数据时的真实风险。期望是在所有可能的数据和标签的（无限）集合上进行的。从我们的愿望出发，要最小化期望风险，引出了两个实际问题，我们将在接下来的两个小节中解决这些问题：

另一个用于期望风险的常用短语是“总体风险”。

我们应该如何改变我们的训练过程以实现良好的泛化？我们如何从有限的数据中估计期望风险？

备注。许多机器学习任务都伴随着一个相关的性能度量，例如预测精度或均方根误差。性能度量可以更复杂，可以是成本敏感的，并且可以捕捉特定应用的细节。原则上，经验风险最小化的损失函数的设计应直接对应于由机器学习任务指定的性能度量。实际上，损失函数的设计与性能度量之间常常存在不匹配。这可能是由于实施简便性或优化效率等问题造成的。$\diamondsuit$

### 8.2.3 正则化以减少过拟合

即使只知道预测器在测试集上的表现也会泄露信息（Blum 和 Hardt，2015 年）。

过拟合

正则化

本节描述了经验风险最小化的一个附加方法，使其能够更好地泛化（近似最小化期望风险）。回想一下，训练机器学习预测器的目标是为了使我们在未见过的数据上表现良好，即预测器具有良好的泛化能力。我们通过保留整个数据集的一部分来模拟这些未见过的数据。这部分保留的数据集被称为**测试集**。给定一个足够丰富的函数类 $f$，我们可以基本上记住训练数据以获得零经验风险。虽然这在最小化训练数据上的损失（因此也是风险）方面很好，但我们不会期望预测器在未见过的数据上泛化得很好。实际上，我们只有有限的数据集，因此我们将数据分为训练集和测试集。训练集用于拟合模型，而测试集（在训练过程中不被机器学习算法看到）用于评估泛化性能。用户在观察测试集后不应回到一个新的训练轮次。我们使用下标 $\scriptstyle{\mathrm{train}}$ 和 $\mathrm{test}$ 分别表示训练集和测试集。我们将在第 8.2.4 节中重新探讨利用有限数据集来评估期望风险的思想。

事实证明，经验风险最小化可能导致**过拟合**，即预测器过于紧密地拟合训练数据，而在新数据上泛化效果不佳（Mitchell，1997 年）。当数据量较少且假设类复杂时，这种现象通常会出现，即在训练集上的平均损失非常小，但在测试集上的平均损失很大。对于某个固定的参数的预测器 $f$，过拟合现象发生在训练数据上的风险估计 ${\bf R}_{\mathrm{emp}}(f,X_{\mathrm{train}},\pmb{y}_{\mathrm{train}})$ 低估了期望风险 $\mathbf{R}_{\mathrm{true}}(f)$。由于我们通过测试集上的经验风险 ${\bf R}_{\mathrm{emp}}(f,X_{\mathrm{test}},\pmb{y}_{\mathrm{test}})$ 估计期望风险 $\mathbf{R}_{\mathrm{true}}(f)$，如果测试风险远大于训练风险，这表明存在过拟合。我们将在第 8.3.3 节中重新讨论过拟合的概念。

因此，我们需要通过引入惩罚项来以某种方式引导经验风险最小化器的搜索，这使得优化器更难以返回过于灵活的预测器。在机器学习中，惩罚项被称为**正则化**。正则化是一种在经验风险最小化精确解和解的大小或复杂度之间妥协的方法。

### 示例 8.3（正则化最小二乘法）

正则化是一种抑制优化问题复杂或极端解的方法。最简单的正则化策略是用“正则化”问题替换最小二乘问题：

$$
\operatorname*{min}_{\pmb{\theta}}\frac{1}{N}\left\|\pmb{y}-\pmb{X}\pmb{\theta}\right\|^{2}\,.
$$

在前一个例子中添加仅涉及 $\pmb{\theta}$ 的惩罚项：

$$
\operatorname*{min}_{\pmb{\theta}}\frac{1}{N}\left\|\pmb{y}-\pmb{X}\pmb{\theta}\right\|^{2}+\lambda\left\|\pmb{\theta}\right\|^{2}\,.
$$

附加项 $\left\Vert\pmb{\theta}\right\Vert^{2}$ 称为**正则化项**，参数 $\lambda$ 称为**正则化参数**。正则化参数在最小化训练集上的损失和参数 $\pmb{\theta}$ 的大小或复杂度之间进行权衡。通常情况下，如果遇到过拟合，参数值的大小会变得相对较大（Bishop，2006 年）。

正则化项有时也称为**惩罚项**，它会使向量 $\pmb{\theta}$ 更接近原点。正则化的思想在概率模型中也表现为参数的先验概率。回顾第 6.6 节，为了使后验分布与先验分布具有相同的形式，先验分布和似然需要是共轭的。我们将在第 8.3.2 节中重新探讨这一思想。在第 12 章中，我们将看到正则化项的想法等同于大间隔的思想。

### 8.2.4 交叉验证以评估泛化性能

我们在上一节提到，我们通过在测试数据上应用预测器来估计其泛化误差，从而测量泛化误差。有时，这种数据也被称为**验证集**。验证集是我们预留的一部分可用训练数据。这种方法的实际问题是数据量有限，理想情况下我们应该尽可能多地使用可用数据来训练模型。这就要求我们保持验证集 $\nu$ 小，这会导致预测性能的噪声估计（高方差）。解决这些矛盾目标（大训练集、大验证集）的一种解决方案是使用**交叉验证**。$K$ 折交叉验证有效地将数据划分为 $K$ 块，其中 $K-1$ 块作为训练集 $\mathcal{R}$，最后一块作为验证集 $\mathcal{V}$（类似于前面概述的想法）。交叉验证迭代遍历（理想情况下）所有分配块到 $\mathcal{R}$ 和 $\nu$ 的组合；参见图 8.4。此过程重复进行 $K$ 次验证集的选择，并对从 $K$ 次运行中模型的性能进行平均。

我们将数据集分为两个集合 $\mathcal{D}=\mathcal{R}\cup\mathcal{V}$，这样它们互不重叠（$\mathcal{R} \cap \mathcal{V} = \emptyset$），其中 $\mathcal{V}$ 是验证集，我们在 $\mathcal{R}$ 上训练我们的模型。训练后，我们在验证集 $\mathcal{V}$ 上评估预测器 $f$ 的性能（例如，通过计算训练模型在验证集上的均方根误差 (RMSE)）。

更具体地说，对于每个划分 $k$，训练数据 $\mathcal{R}^{(k)}$ 生成预测器 $f^{(k)}$，然后应用于验证集 $\mathcal{V}^{(k)}$ 计算经验风险 $R(f^{(k)}, \mathcal{V}^{(k)})$。我们循环遍历所有可能的验证集和训练集划分组合，并计算预测器的平均泛化误差。交叉验证近似期望泛化误差

$$
\mathbb{E}_{\mathcal{V}}[R(f,\mathcal{V})] \approx \frac{1}{K} \sum_{k=1}^{K} R(f^{(k)}, \mathcal{V}^{(k)})\,,
$$

其中 $R(f^{(k)}, \mathcal{V}^{(k)})$ 是验证集 $\mathcal{V}^{(k)}$ 上预测器 $f^{(k)}$ 的风险（例如，RMSE）。这个近似的来源有两个：首先，由于有限的训练集，导致不是最优的 $f^{(k)}$；其次，由于有限的验证集，导致风险 $R(f^{(k)}, \mathcal{V}^{(k)})$ 的估计不准确。$K$ 折交叉验证的一个潜在缺点是训练模型 $K$ 次的计算成本，如果训练成本计算昂贵，这可能会很耗时。实际上，通常不仅仅看直接参数。例如，我们需要探索多个复杂参数（例如，多个正则化参数），这些参数可能不是模型的直接参数。根据这些超参数评估模型的质量可能导致训练次数呈指数增长。可以使用嵌套交叉验证（第 8.6.1 节）来搜索好的超参数。

嵌入式并行

然而，交叉验证是一个**嵌入式并行**问题，即几乎不需要努力将问题分解成多个并行任务。给定足够的计算资源（例如，云计算、服务器农场），交叉验证不需要比一次性能评估更长的时间。

在本节中，我们了解到经验风险最小化基于以下概念：函数假设类、损失函数和正则化。在第 8.3 节中，我们将看到使用概率分布来代替损失函数和正则化的效果。

### 8.2.5 进一步阅读

由于经验风险最小化（Vapnik，1998）最初的发展是在高度理论化的语言背景下进行的，因此后续发展的许多都是理论性的。这个研究领域被称为**统计学习理论**（Vapnik，1999；Evgeniou 等人，2000；Hastie 等人，2001；von Luxburg 和 Schölkopf，2011）。最近一本基于理论基础并开发高效学习算法的机器学习教科书是 Shalev-Shwartz 和 Ben-David（2014）。

统计学习理论

正则化的概念源自于病态逆问题的求解（Neumaier，1998）。这里介绍的方法称为**Tikhonov 正则化**，与之密切相关的是一个约束版本，称为**Ivanov 正则化**。Tikhonov 正则化与偏差-方差权衡和特征选择有着深刻的联系（Bühlmann 和 Van De Geer，2011）。交叉验证的替代方案是自助法和刀切法（Efron 和 Tibshirani，1993；Davidson 和 Hinkley，1997；Hall，1992）。

Tikhonov 正则化

将经验风险最小化（第 8.2 节）视为“无概率”的是不正确的。有一个未知的概率分布 $p(\pmb{x}, y)$ 控制数据生成。然而，经验风险最小化的方法对此分布的选择是不知情的。这与标准统计方法明确要求 $p(\pmb{x}, \pmb{y})$ 的知识不同。此外，由于分布是对示例 $\pmb{x}$ 和标签 $y$ 的联合分布，标签可以是非确定性的。与标准统计不同，我们不需要为标签 $y$ 指定噪声分布。

## 8.3 参数估计

在第 8.2 节中，我们没有显式地使用概率分布来建模问题。在本节中，我们将看到如何使用概率分布来建模由于观测过程以及预测器参数不确定性引起的不确定性。在第 8.3.1 节中，我们引入了似然性，它与经验风险最小化中的损失函数（第 8.2.2 节）的概念类似。先验（第 8.3.2 节）的概念与正则化（第 8.2.3 节）的概念类似。

### 8.3.1 最大似然估计

**最大似然估计**（Maximum Likelihood Estimation, MLE）的基本思想是定义一个关于参数的函数，使我们能够找到一个很好地拟合数据的模型。估计问题集中在**似然函数**，或者更精确地说是它的负对数。对于表示为随机变量 $\pmb{x}$ 的数据和参数化为 $\pmb{\theta}$ 的概率密度族 $p(\pmb{x}\,|\,\pmb{\theta})$，**负对数似然**定义为

$$
\mathcal{L}_{\pmb{x}}(\pmb{\theta})=-\log p(\pmb{x}\,|\,\pmb{\theta})\,.
$$

记号 $\mathcal{L}_{\pmb{x}}(\pmb{\theta})$ 强调了参数 $\pmb{\theta}$ 在变化而数据 $\pmb{x}$ 固定的事实。当我们书写负对数似然时，通常会省略对 $\pmb{x}$ 的引用，因为它是关于 $\pmb{\theta}$ 的函数，当数据中的不确定性随机变量明确时，我们可以写作 $\mathcal{L}(\pmb{\theta})$。

让我们解释固定 $\pmb{\theta}$ 值时概率密度 $p(\pmb{x}\,|\,\pmb{\theta})$ 所建模的内容。它是一个分布，用于建模给定参数设置下的数据不确定性。对于给定的数据集 $\pmb{x}$ ，似然性允许我们表达对参数 $\pmb{\theta}$ 不同设置的偏好，并且我们可以选择更“可能”生成数据的设置。

从互补的角度来看，如果我们认为数据是固定的（因为已经被观察到），并且我们改变参数 $\pmb{\theta}$，那么 $\mathcal{L}(\pmb{\theta})$ 告诉我们 $\pmb{\theta}$ 的特定设置对于观测数据 $\pmb{x}$ 的可能性。基于这个第二个视角，最大似然估计器给出了数据集中最可能的参数 $\pmb{\theta}$。

我们考虑监督学习设置，在该设置下我们获得配对 $(\pmb{x}_{1},y_{1}),\dots,(\pmb{x}_{N},y_{N})$，其中 $\pmb{x}_{n}\,\in\,\mathbb{R}^{D}$ 和标签 $y_{n}\in\mathbb{R}$。我们感兴趣的是构建一个预测器，该预测器将特征向量 $\pmb{x}_{n}$ 作为输入并产生预测 $y_{n}$（或接近的值），即给定向量 $\pmb{x}_{n}$，我们希望得到标签 $y_{n}$ 的概率分布。换句话说，我们指定了在特定参数设置 $\pmb{\theta}$ 下，给定示例的标签条件概率分布。

### 示例 8.4

一个常用的例子是假设标签给定示例的条件概率是高斯分布。换句话说，我们假设可以通过独立的零均值高斯噪声（参考第 6.5 节）来解释我们的观测不确定性，$\varepsilon_{n}\sim\mathcal{N}\big(0,\,\sigma^{2}\big)$。我们进一步假设线性模型 $\mathbf{\Delta}\mathbf{\mathcal{X}}_{n}^{\top}\mathbf{\theta}$ 用于预测。这意味着我们为每个示例标签对 $(\pmb{x}_{n},y_{n})$ 指定一个高斯似然性，

$$
p(y_{n}\,|\,\mathbf{x}_{n},\pmb\theta)=\mathcal{N}\big(y_{n}\,|\,\mathbf{x}_{n}^{\top}\pmb\theta,\,\sigma^{2}\big)\,.
$$

图 8.3 显示了给定参数 $\pmb{\theta}$ 的高斯似然性的示意图。在第 9.2 节中，我们将看到如何显式地将上述表达式扩展为高斯分布的形式。

我们假设示例集 $(x_{1},y_{1}),.\,.\,.\,,(x_{N},y_{N})$ 是**独立同分布**（i.i.d.）。单词“独立”（第 6.4.5 节）意味着涉及整个数据集 $(\mathcal{Y}=\{y_{1},\cdot\cdot\cdot,y_{N}\}$ 和 $\mathcal{X}=\{\pmb{x}_{1},.\,.\,.\,,\pmb{x}_{N}\})$ 的似然性可以分解为每个单独示例似然性的乘积，

$$
p(\mathcal{Y}\,|\,\mathcal{X},\pmb{\theta})=\prod_{n=1}^{N}p(y_{n}\,|\,\pmb{x}_{n},\pmb{\theta})\,,
$$

其中 $p(y_{n}\,|\,\pmb{x}_{n},\pmb{\theta})$ 是一个特定的分布（在示例 8.4 中是高斯分布）。术语“同分布”意味着乘积（8.16）中的每一项都具有相同的分布，并且所有项共享相同的参数。从优化的角度来看，通常更容易计算可以分解为简单函数之和的函数。因此，在机器学习中，我们经常考虑负对数似然

$$
\mathcal{L}(\pmb{\theta})=-\log p(\mathcal{Y}\,|\,\mathcal{X},\pmb{\theta})=-\sum_{n=1}^{N}\log p(y_{n}\,|\,\pmb{x}_{n},\pmb{\theta})\,.
$$

虽然容易将 $\pmb{\theta}$ 解释为 $p(y_{n}|\pmb{x}_{n},\pmb{\theta})$（8.15）中条件右侧的观测和固定值，但这种解释是不正确的。负对数似然 $\mathcal{L}(\pmb{\theta})$ 是关于 $\pmb{\theta}$ 的函数。因此，为了找到一个好的参数向量 $\pmb{\theta}$，该参数向量很好地解释了数据 $(\pmb{x}_{1},y_{1}),\dots,(\pmb{x}_{N},y_{N})$，需要最小化负对数似然 $\mathcal{L}(\pmb{\theta})$ 关于 $\pmb{\theta}$。

备注。公式（8.17）中的负号是历史遗留的惯例，我们希望最大化似然性，但数值优化文献倾向于研究函数的最小化。$\diamondsuit$

### 示例 8.5

继续我们的高斯似然性示例（8.15），负对数似然可以重写为

$$
\begin{aligned}
&\mathcal{L}(\pmb{\theta})=-\sum_{n=1}^{N}\log p(y_{n}\mid\pmb{x}_{n},\pmb{\theta})=-\sum_{n=1}^{N}\log \mathcal{N}(y_{n}\mid\pmb{x}_{n}^{\top}\pmb{\theta},\,\sigma^{2}) \\
&\quad\quad\quad=-\sum_{n=1}^{N}\log{\frac{1}{\sqrt{2\pi\sigma^{2}}}}\exp\left(-{\frac{(y_{n}-\pmb{x}_{n}^{\top}\pmb{\theta})^{2}}{2\sigma^{2}}}\right) \\
&\quad\quad\quad=-\sum_{n=1}^{N}\log\exp\left(-{\frac{(y_{n}-\pmb{x}_{n}^{\top}\pmb{\theta})^{2}}{2\sigma^{2}}}\right)-\sum_{n=1}^{N}\log{\frac{1}{\sqrt{2\pi\sigma^{2}}}} \\
&\quad\quad\quad={\frac{1}{2\sigma^{2}}}\sum_{n=1}^{N}(y_{n}-\pmb{x}_{n}^{\top}\pmb{\theta})^{2}-\sum_{n=1}^{N}\log{\frac{1}{\sqrt{2\pi\sigma^{2}}}}\,.
\end{aligned}
$$

由于 $\sigma$ 已知，(8.18d) 中的第二项是常数，最小化 $\mathcal{L}(\pmb{\theta})$ 相当于求解第一个项表示的最小二乘问题（参见（8.8））。

结果表明，对于高斯似然性，对应的优化问题有一个闭式解。我们在第 9 章中会看到更多细节。图 8.5 显示了一个回归数据集和由最大似然参数诱导的函数。最大似然估计可能会出现过拟合（第 8.3.3 节），类似于未正则化的经验风险最小化（第 8.2.3 节）。对于其他似然函数，即如果我们将噪声建模为非高斯分布，最大似然估计可能没有闭式解析解。在这种情况下，我们求助于第 7 章讨论的数值优化方法。

### 8.3.2 最大后验估计

如果我们有关于参数 $\pmb{\theta}$ 分布的先验知识，可以在似然性上乘以一个附加项。这个附加项是参数上的先验概率分布 $p(\pmb\theta)$。对于给定的先验，在观察了一些数据 $_{\pmb{x}}$ 后，我们应该如何更新 $\pmb{\theta}$ 的分布？换句话说，我们应该如何表示在观察数据 $_{x}$ 后我们对 $\pmb{\theta}$ 有更具体的知识？正如第 6.3 节讨论的贝叶斯定理，为我们提供了一种更新随机变量概率分布的原则工具。它允许我们计算一个**后验**分布 $p(\pmb\theta\,|\,\pmb x)$（更具体的知识），通过一般先验声明（先验分布）$p(\pmb\theta)$ 和函数 $p(\pmb{x}\,|\,\pmb{\theta})$，后者将参数 $\theta$ 和观测数据 $x$ 联系起来（称为**似然**）：

$$
p(\pmb\theta\,|\,\pmb x)=\frac{p(\pmb x\,|\,\pmb\theta)p(\pmb\theta)}{p(\pmb x)}\,.
$$

回想一下，我们感兴趣的参数 $\pmb{\theta}$ 是最大化后验的参数。由于分布 $p(\pmb{x})$ 不依赖于 $\pmb{\theta}$，我们可以忽略分母的值以进行优化，并得到

$$
p(\pmb\theta\,|\,\pmb x)\propto p(\pmb x\,|\,\pmb\theta)p(\pmb\theta)\,.
$$

前面的比例关系隐藏了数据密度 $p(\pmb{x})$，这可能难以估计。我们现在估计负对数后验的最小值，而不是负对数似然的最小值，这被称为**最大后验估计**（MAP 估计）。图 8.6 显示了添加零均值高斯先验的效果。

### 示例 8.6

除了前一示例中的高斯似然假设外，我们假设参数向量分布为零均值的多元高斯分布，即 $p(\pmb\theta)=\mathcal{N}(\mathbf0,\,\Sigma)$，其中 $\pmb{\Sigma}$ 是协方差矩阵（第 6.5 节）。注意，高斯分布的共轭先验也是高斯分布（第 6.6.1 节），因此我们期望后验分布也是高斯分布。我们将在第 9 章中看到最大后验估计的详细内容。

在机器学习中，包括关于良好参数所在位置的先验知识的思想非常普遍。另一种观点，我们曾在第 8.2.3 节中看到，是正则化思想，它引入了一个额外的项，使结果参数偏向于接近原点。最大后验估计可以被认为是在非概率和概率世界之间架起桥梁，因为它明确承认需要一个先验分布，但仍只产生参数的点估计。

备注。最大似然估计 $\pmb{\theta}_{\mathrm{ML}}$ 具有以下性质（Lehmann 和 Casella，1998；Efron 和 Hastie，2016）：

**渐近一致性**：在无穷多观测的极限下，MLE 收敛到真实值，加上一个近似正态的随机误差。达到这些性质所需的样本大小可能相当大。误差的方差以 $1/N$ 衰减，其中 $N$ 是数据点的数量。特别是在“小”数据情况下，最大似然估计可能导致过拟合。

最大似然估计（和最大后验估计）的原则使用概率建模来推理数据和模型参数的不确定性。然而，我们尚未完全利用概率建模。在本节中，产生的训练过程仍然产生预测器的点估计，即训练返回一组参数值，代表最佳预测器。在第 8.4 节中，我们将采取参数值也应被视为随机变量的观点，并且在进行预测时，我们将使用完整的参数分布，而不是估计其“最佳”值。

### 8.3.3 模型拟合

考虑我们有一个数据集，并且我们有兴趣将一个参数化的模型拟合到这些数据上。当我们谈论“拟合”时，通常是指优化/学习模型参数，使它们最小化某个损失函数，例如负对数似然。在最大似然（第 8.3.1 节）和最大后验估计（第 8.3.2 节）中，我们已经讨论了两种常用的模型拟合算法。

模型的参数化定义了一个模型类 \( M_{\theta} \)，我们可以对其进行操作。例如，在线性回归设置中，我们可能定义输入 \( x \) 和（无噪声）观测值 \( y \) 之间的关系为 \( y = ax + b \)，其中 \(\pmb{\theta} := \{a, b\}\) 是模型参数。在这种情况下，模型参数 \(\theta\) 描述了一族仿射函数，即斜率为 \( a \) 的直线，这些直线从 \( 0 \) 偏移了 \( b \)。假设数据来自一个我们未知的模型 \( M^{*} \)。对于给定的训练数据集，我们优化 \(\pmb{\theta}\) 使得 \( M_{\theta} \) 尽可能接近 \( M^{*} \)，其中“接近”由我们优化的目标函数定义（例如，训练数据上的平方损失）。图 8.7 说明了一个我们拥有较小模型类（由圆 \( M_{\pmb{\theta}} \) 表示）的情况，而数据生成模型 \( M^{*} \) 超出了我们考虑的模型集合。我们在 \( M_{\theta_{0}} \) 开始参数搜索。经过优化后，即当我们获得最佳可能的参数 \(\pmb{\theta}^{*}\) 后，我们将区分三种不同的情况：(i) 过拟合，(ii) 欠拟合，和 (iii) 拟合良好。我们将给出这三个概念的高层次直觉。

粗略地说，**过拟合**是指参数化模型类过于丰富以至于无法模拟由 \( M^{*} \) 生成的数据集，即 \( M_{\theta} \) 可以模拟更复杂的多种数据集。例如，如果数据集是由线性函数生成的，而我们定义 \( M_{\theta} \) 为七次多项式类，我们不仅能够模拟线性函数，还能模拟二次、三次等不同次数的多项式。过拟合的模型通常具有大量的参数。我们经常观察到的是，过度灵活的模型类 \( M_{\theta} \) 使用其全部建模能力来减少训练误差。因此，如果训练数据是嘈杂的，它会找到噪声中的某些有用信号。这会导致在预测远离训练数据时出现巨大问题。图 8.8(a) 给出了一个回归背景下过拟合的例子，其中模型参数通过最大似然方法学习（见第 8.3.1 节）。我们将在第 9.2.2 节中更详细地讨论回归中的过拟合。

当我们遇到**欠拟合**时，我们会遇到相反的问题，即模型类 \( M_{\theta} \) 不够丰富。例如，如果我们的数据集是由正弦函数生成的，但 \(\pmb{\theta}\) 只参数化直线，那么最好的优化过程也无法让我们接近真实模型。然而，我们仍然优化参数并找到最能模拟数据集的直线。图 8.8(b) 显示了一个由于不够灵活而欠拟合的模型。欠拟合的模型通常具有较少的参数。

**过拟合**

在实践中检测过拟合的一种方法是观察到模型在交叉验证期间具有低训练风险但高测试风险（第 8.2.4 节）。

**欠拟合**

第三种情况是参数化模型类大约合适。这样，我们的模型拟合得很好，即既不过拟合也不欠拟合。这意味着我们的模型类刚好足够描述我们所给的数据集。图 8.8(c) 显示了一个拟合给定数据集较好的模型。理想情况下，这就是我们想要使用的模型类，因为它具有良好的泛化性能。

实际上，我们常常定义非常丰富的模型类 \( M_{\theta} \)，包含许多参数，例如深度神经网络。为了缓解过拟合问题，我们可以使用正则化（第 8.2.3 节）或先验（第 8.3.2 节）。我们将在第 8.6 节中讨论如何选择模型类。

### 8.3.4 进一步阅读

当考虑概率模型时，最大似然估计推广了线性模型的最小二乘回归的思想，我们将在第 9 章详细讨论这一点。当限制预测器的形式为线性形式加上一个应用于输出的非线性函数 \(\varphi\)，即

$$
p(y_{n}|\pmb{x}_{n},\pmb{\theta})=\varphi(\pmb{\theta}^{\top}\pmb{x}_{n})\,,
$$

我们可以考虑其他预测任务的模型，例如二分类或计数数据建模（McCullagh 和 Nelder，1989）。另一种观点是从指数族（第 6.6 节）的角度考虑似然函数。具有参数和数据之间线性依赖关系且具有潜在非线性变换 \(\varphi\)（称为链接函数）的模型类被称为广义线性模型（Agresti，2002，第 4 章）。

最大似然估计具有丰富的历史，最初由 Ronald Fisher 男爵在 1930 年代提出。我们将在第 8.4 节中扩展概率模型的概念。在使用概率模型的研究人员中，一种争论是贝叶斯统计与频率学派统计之间的讨论。正如第 6.1.1 节所述，这归结于概率的定义。回忆第 6.1 节，可以认为概率是一种逻辑推理的一般化（通过允许不确定性）。最大似然估计的方法本质上是频率学派的，感兴趣的读者可以参考 Efron 和 Hastie（2016）以获得关于贝叶斯和频率学派统计的平衡视角。

有一些概率模型中，最大似然估计可能是不可能实现的。读者可以参考更高级的统计教科书，例如 Casella 和 Berger（2002），以了解诸如矩法、\( M \) 估计和估计方程等方法。

## 8.4 概率建模与推理

生成过程在机器学习中，我们经常关注数据的解释和分析，例如预测未来事件和决策制定。为了使这项任务更加可行，我们通常构建模型来描述生成观测数据的生成过程。

例如，我们可以用两步来描述抛硬币实验（“正面”或“反面”）的结果。首先，我们定义一个参数 $\mu$，它描述了“正面”的概率作为伯努利分布（第6章）的参数；其次，我们可以从伯努利分布 $p(x\,|\,\mu)=\mathtt{Ber}(\mu)$ 中抽取结果 $x\in\{\mathrm{正面}, \mathrm{反面}\}$。参数 $\mu$ 生成了一个特定的数据集 $X$，并取决于所使用的硬币。由于 $\mu$ 在事先未知且无法直接观察到，我们需要机制来根据抛硬币实验的观测结果了解 $\mu$。在下文中，我们将讨论如何使用概率建模来实现这一目的。

### 8.4.1 概率模型

概率模型将实验中的不确定方面表示为概率分布。使用概率模型的好处在于，它们提供了来自概率论（第6章）的一套统一且一致的工具，用于建模、推理、预测和模型选择。

概率模型由所有随机变量的联合分布指定。

在概率建模中，观测变量 $\pmb{x}$ 和隐藏参数 $\pmb{\theta}$ 的联合分布 $p(\pmb{x},\pmb{\theta})$ 是至关重要的：它封装了以下信息：

- 先验和似然（乘法规则，第6.3节）。边缘似然 $p(\pmb{x})$ 在模型选择（第8.6节）中起重要作用，可以通过对联合分布进行积分（求和规则，第6.3节）来计算。后验分布，通过将联合分布除以边缘似然获得。

只有联合分布具有这种属性。因此，概率模型由其所有随机变量的联合分布指定。

### 8.4.2 贝叶斯推理

在机器学习中，一个关键任务是从模型和数据中揭示模型隐藏变量 $\pmb{\theta}$ 的值，给定观测变量 $\pmb{x}$。在第8.3.1节中，我们已经讨论了两种使用最大似然估计或最大后验估计来估计模型参数 $\pmb{\theta}$ 的方法。在这两种情况下，我们都会得到一个单一的最佳值 $\pmb{\theta}$，因此参数估计的关键算法问题是解决优化问题。一旦这些点估计 $\pmb{\theta}^{*}$ 已知，我们就可以用它们来做预测。具体而言，预测分布将是 $p(\pmb{x}\mid\pmb{\theta}^{*})$，其中我们在似然函数中使用 $\pmb{\theta}^{*}$。

参数估计可以表述为一个优化问题。

正如第6.3节所述，仅关注后验分布的一些统计量（例如最大化后验的参数 $\pmb{\theta}^{*}$）会导致信息丢失，这在贝叶斯推理中是关于学习随机变量的分布时可能会非常关键的问题。贝叶斯推理

使用预测 $p(\pmb{x}\mid\pmb{\theta}^{*})$ 来做决策。这些决策系统通常具有不同于似然函数的目标函数，例如平方误差损失或误分类误差。因此，拥有完整的后验分布是非常有用的，并且会带来更稳健的决策。**贝叶斯推理**是找到这个后验分布的过程（Gelman等，2004）。对于数据集 $\mathcal{X}$、参数先验 $p(\pmb{\theta})$ 和似然函数，后验分布

$$
p(\pmb{\theta}\,|\,\mathcal{X})=\frac{p(\mathcal{X}\,|\,\pmb{\theta})p(\pmb{\theta})}{p(\mathcal{X})}\,,\qquad p(\mathcal{X})=\int p(\mathcal{X}\,|\,\pmb{\theta})p(\pmb{\theta})\mathrm{d}\pmb{\theta}\,,
$$

贝叶斯推理反转了参数和数据之间的关系。

通过应用贝叶斯定理获得。关键思想是利用贝叶斯定理来反转参数 $\pmb{\theta}$ 和数据 $\mathcal{X}$（由似然函数给出）之间的关系，以获得后验分布 $p(\pmb{\theta}\,|\,\mathcal{X})$。

拥有后验分布对参数的影响是它可以用来将参数的不确定性传播到数据中。更具体地说，如果我们有一个参数分布 $p(\pmb{\theta})$，我们的预测将是

$$
p(\pmb{x})=\int p(\pmb{x}\,|\,\pmb{\theta})p(\pmb{\theta})\mathrm{d}\pmb{\theta}=\mathbb{E}_{\pmb{\theta}}[p(\pmb{x}\,|\,\pmb{\theta})]\,,
$$

并且它们不再依赖于已经边际化/积分出去的模型参数 $\pmb{\theta}$。方程(8.23)表明预测是对所有可能的参数值 $\pmb{\theta}$ 的平均，而可能性由参数分布 $p(\pmb{\theta})$ 封装。

在第8.3节讨论了参数估计并在本节讨论了贝叶斯推理之后，让我们比较这两种学习方法。通过最大似然估计或最大后验估计进行参数估计会产生参数的一致点估计 $\pmb{\theta}^{*}$，而关键的计算问题是优化。相反，贝叶斯推理产生（后验）分布，而关键的计算问题是积分。使用点估计进行预测是直接的，而在贝叶斯框架下进行预测需要解决另一个积分问题；见（8.23）。然而，贝叶斯推理为我们提供了一种有原则的方法来纳入先验知识、考虑侧信息以及纳入结构知识，所有这些在参数估计的背景下都不容易实现。此外，在数据高效学习的背景下，参数不确定性向预测的传播在决策系统中进行风险评估和探索时可能是有价值的（Deisenroth等，2015；Kamthe和Deisenroth，2018）。

尽管贝叶斯推理是一个数学上合理的学习参数和进行预测的框架，但由于我们需要解决的积分问题，它也带来了一些实际挑战；参见（8.22）和（8.23）。更具体地说，如果我们没有选择参数上的共轭先验（第6.6.1节），那么（8.22）和（8.23）中的积分就不是解析可解的，我们无法以封闭形式计算后验、预测或边缘似然。在这种情况下，我们需要诉诸近似方法。这里，我们可以使用随机近似，例如马尔科夫链蒙特卡洛（MCMC）（Gilks等，1996），或者确定性近似，例如拉普拉斯近似（Bishop，2006；Barber，2012；Murphy，2012），变分推理（Jordan等，1999；Blei等，2017），或期望传播（Minka，2001a）。

尽管存在这些挑战，贝叶斯推理已被成功应用于各种问题，包括大规模主题建模（Hoffman等，2013）、点击率预测（Graepel等，2010）、控制系统中的数据高效强化学习（Deisenroth等，2015）、在线排名系统（Herbrich等，2007）和大规模推荐系统。有一些通用工具，例如贝叶斯优化（Brochu等，2009；Snoek等，2012；Shahriari等，2016），这些工具是高效搜索模型或算法的元参数的有效组成部分。

**备注** 在机器学习文献中，（随机）“变量”和“参数”之间可能存在某种任意分离。虽然参数是通过最大似然等方法估计的，但变量通常是被边缘化的。在这本书中，我们并不严格区分这种分离，因为原则上，我们可以对任何参数放置一个先验并对其进行积分，这将根据上述分离将参数变成一个随机变量。$\diamondsuit$

### 8.4.3 潜变量模型

在实践中，有时在模型中引入额外的潜变量 $_z$（除了模型参数 $\pmb{\theta}$ 之外）是有用的（Moustaki 等，2015）。这些潜变量不同于模型参数 $\pmb{\theta}$，因为它们并不显式地参数化模型。潜变量可能描述数据生成过程，从而提高模型的可解释性。它们通常简化了模型结构，并允许我们定义更简单且更丰富的模型结构。模型结构的简化往往伴随着较少数量的模型参数（Paquet，2008；Murphy，2012）。在潜变量模型中学习（至少通过最大似然法）可以使用期望最大化（EM）算法进行（Dempster 等，1977；Bishop，2006）。潜变量对以下模型是有帮助的例子包括降维的主成分分析（第 10 章）、密度估计的高斯混合模型（第 11 章）、时间序列建模的隐马尔可夫模型（Maybeck，1979）或动态系统（Ghahramani 和 Roweis，1999；Ljung，1999），以及元学习和任务泛化（Hausman 等，2018；Sæmundsson 等，2018）。尽管引入这些潜变量可以使模型结构和生成过程更加容易理解，但在潜变量模型中学习通常是困难的，正如我们在第 11 章所看到的。

由于潜变量模型也允许我们从参数定义数据生成过程，让我们看一下这个生成过程。表示数据为 $\pmb{x}$，模型参数为 $\pmb{\theta}$，潜变量为 $_z$，我们得到条件分布

$$
p(\pmb{x}\,|\,z,\pmb{\theta})
$$

这使我们能够根据任意模型参数和潜变量生成数据。鉴于 $_z$ 是潜变量，我们在其上放置一个先验 $p(z)$。

如同前面讨论的模型，具有潜变量的模型可以在我们在第 8.3 节和第 8.4.2 节讨论的框架内用于参数学习和推理。为了便于学习（例如，通过最大似然估计或贝叶斯推理），我们遵循两步程序。首先，我们计算模型的似然度 $p(\pmb{x}\,|\,\pmb{\theta})$，它不依赖于潜变量。其次，我们使用此似然度进行参数估计或贝叶斯推理，在这里我们使用与第 8.3 节和第 8.4.2 节相同的表达式。

由于似然函数 $p(\pmb{x}\,|\,\pmb{\theta})$ 是给定模型参数的数据预测分布，我们需要对潜变量进行边缘化，因此

$$
p(\pmb{x}\,|\,\pmb{\theta})=\int p(\pmb{x}\,|\,z,\pmb{\theta})p(z)\mathrm{d}z\,,
$$

似然度是数据和模型参数的函数，但独立于潜变量。

其中 $p(\pmb{x}\,|\,z,\pmb{\theta})$ 如（8.24）所示，$p(z)$ 是潜变量上的先验。请注意，似然度不得依赖于潜变量 $_z$，而只能是数据 $\pmb{x}$ 和模型参数 $\pmb{\theta}$ 的函数。

在（8.25）中的似然度可以直接通过最大似然进行参数估计。如果在模型参数 $\pmb{\theta}$ 上有一个附加的先验，MAP 估计也很直接，如第 8.3.2 节所述。此外，有了似然度（8.25），在潜变量模型中的贝叶斯推理（第 8.4.2 节）以常规方式工作：我们在模型参数上放置一个先验 $p(\pmb\theta)$ 并使用贝叶斯定理来获得一个后验分布

$$
p(\pmb\theta\,|\,\mathcal X)=\frac{p(\mathcal X\,|\,\pmb\theta)p(\pmb\theta)}{p(\mathcal X)}
$$

给定一个数据集 $\mathcal{X}$ 的模型参数后验。在（8.26）中的后验可以在贝叶斯推理框架内用于预测；见（8.23）。

在这个潜变量模型中的一个挑战是似然度 $p(\mathcal{X}\,|\,\pmb\theta)$ 需要根据（8.25）对潜变量进行边缘化。除非我们选择一个与 $p(\pmb{x}\,|\,z,\pmb{\theta})$ 相匹配的先验 $p(z)$，否则（8.25）中的边缘化不是解析可解的，我们需要求助于近似（Bishop，2006；Paquet，2008；Murphy，2012；Moustaki 等，2015）。

类似于参数后验（8.26），我们可以根据

$$
p(z\,|\,\mathcal{X})=\frac{p(\mathcal{X}\,|\,z)p(z)}{p(\mathcal{X})}\,,\qquad p(\mathcal{X}\,|\,z)=\int p(\mathcal{X}\,|\,z,\theta)p(\theta)\mathrm{d}\theta\,,
$$

计算潜变量的后验，其中 $p(z)$ 是潜变量上的先验，$p(\mathcal{X}\,|\,z)$ 要求我们对模型参数 $\theta$ 进行积分。

鉴于解析积分的难度，显然同时边缘化潜变量和模型参数通常是不可能的（Bishop，2006；Murphy，2012）。一个更容易计算的量是给定模型参数的潜变量的后验分布，即

$$
p(z\mid\mathcal{X},\pmb\theta)=\frac{p(\mathcal{X}\mid z,\pmb\theta)p(z)}{p(\mathcal{X}\mid\pmb\theta)}\,,
$$

其中 $p(z)$ 是潜变量上的先验，$p(\mathcal{X}\,|\,z,\pmb\theta)$ 如（8.24）所示。

在第 10 章和第 11 章中，我们将推导主成分分析和高斯混合模型的似然函数。此外，我们还将计算这两种模型的潜变量的后验分布（8.28）。

备注。 在后续章节中，我们可能不会明确区分潜变量 $_z$ 和不确定的模型参数 $\pmb{\theta}$，并称模型参数为“潜”或“隐藏”的，因为它们是未观测到的。在第 10 章和第 11 章中，当我们使用潜变量 $_z$ 时，我们会注意到区别，因为我们会有两种不同类型的隐藏变量：模型参数 $\pmb{\theta}$ 和潜变量 $_z$。$\diamondsuit$

我们可以利用概率模型的所有元素都是随机变量这一事实，定义一种统一的语言来表示它们。在第 8.5 节中，我们将看到一种简洁的图形语言来表示概率模型的结构。我们将使用这种图形语言来描述后续章节中的概率模型。

### 8.4.4 进一步阅读

机器学习中的概率模型（Bishop，2006；Barber，2012；Murphy，2012）提供了一种用户以合理的方式捕捉数据和预测模型的不确定性的方式。Ghahramani（2015）概述了机器学习中的概率模型。给定一个概率模型，我们可能会足够幸运地能够解析地计算感兴趣的参数。然而，一般情况下，解析解很少见，计算方法如采样（Gilks 等，1996；Brooks 等，2011）和变分推理（Jordan 等，1999；Blei 等，2017）被使用。Moustaki 等（2015）和 Paquet（2008）提供了关于潜变量模型中贝叶斯推理的良好概述。

概率编程

有向图模型

有向图模型也称为贝叶斯网络。

图模型

近年来，提出了几种旨在将软件中定义的变量视为对应于概率分布的随机变量的编程语言。目标是能够编写概率分布的复杂函数，而底层编译器自动处理贝叶斯推理的规则。这一快速发展的领域被称为概率编程。

## 8.5 有向图模型

在本节中，我们将介绍一种用于指定概率模型的图形语言，称为**有向图模型**。它提供了一种紧凑且简洁的方式来指定概率模型，并允许读者通过视觉解析随机变量之间的依赖关系。有向图模型通过图形方式捕捉了联合分布如何分解为仅依赖于这些变量子集的因子。在第 8.4 节中，我们确定了概率模型的联合分布作为关键量，因为它包含了关于先验、似然和后验的信息。然而，联合分布本身可能相当复杂，并且不能告诉我们关于概率模型结构属性的任何信息。例如，联合分布 \( p(a,b,c) \) 并没有告诉我们关于独立性的任何信息。这就是有向图模型发挥作用的地方。本节依赖于第 6.4.5 节中描述的独立性和条件独立性概念。

在**有向图模型**中，节点代表随机变量。在图 8.9(a) 中，节点表示随机变量 \( a, b, c \)。边表示变量之间的概率关系，例如条件概率。

> 备注：并非每个分布都可以用特定选择的有向图模型来表示。关于这一点的讨论可以在 Bishop (2006) 中找到。$\diamondsuit$

概率图模型具有一些方便的性质：

它们是一种简单的方法来可视化概率模型的结构。它们可以用来设计或激励新的统计模型类型。单独检查图形即可让我们获得对模型属性的洞察，例如条件独立性。统计模型中复杂的推断和学习计算可以通过图形操作来表达。

## 8.5.1 图的语义

### 有向图模型/贝叶斯网络

有向图模型/贝叶斯网络是一种表示概率模型中条件依赖的方法。它们提供了条件概率的视觉描述，因此提供了一种简单的语言来描述复杂的相互依赖关系。这种模块化描述还带来了计算上的简化。两个节点（随机变量）之间的有向连接（箭头）表示条件概率。例如，在图 8.9(a) 中，\( a \) 和 \( b \) 之间的箭头给出了给定 \( a \) 的条件下 \( b \) 的条件概率 \( p(b|a) \)。

在附加假设下，箭头还可以用来指示因果关系（Pearl, 2009）。

![](images/abe6a56c04d382442eb20c4a718f82393c7e6fa8fa5496ef6dd0480f8f5f3721.jpg)
图 8.9 有向图模型示例。

如果知道一些关于联合分布分解的信息，可以从联合分布中推导出有向图模型。

### 示例 8.7

考虑联合分布

$$
p(a,b,c)=p(c\,|\,a,b)p(b\,|\,a)p(a)
$$

的三个随机变量 $a,b,c$。式（8.29）中联合分布的因式分解告诉我们这些随机变量之间的关系：

$c$ 直接依赖于 $a$ 和 $b$。$b$ 直接依赖于 $a$。$a$ 不依赖于 $b$ 或 $c$。

对于式（8.29）中的因式分解，我们得到图 8.9(a) 中的有向图模型。

一般来说，我们可以从一个因式化的联合分布构造相应的有向图模型，如下所示：

1. 为所有随机变量创建节点。
2. 对于每个条件分布，我们从图中对应变量的节点添加一条有向边（箭头）到图中。

图的布局取决于联合分布的因式分解选择。

我们讨论了如何根据已知的联合分布的因式分解来获得相应的有向图模型。现在，我们将做相反的事情，描述如何从给定的图模型中提取一组随机变量的联合分布。

### 示例 8.8

观察图 8.9(b) 中的图模型，我们利用两个性质：

所求的联合分布 $p(x_{1},\dots,x_{5})$ 是图中每个节点对应的条件分布的乘积。在这个特定的例子中，我们需要五个条件分布。每个条件分布只依赖于图中相应节点的父节点。例如，$x_{4}$ 将被条件化为 $x_{2}$。

这两个性质给出了联合分布所需的因式分解

$$
p(x_{1},x_{2},x_{3},x_{4},x_{5})=p(x_{1})p(x_{5})p(x_{2}\mid x_{5})p(x_{3}\mid x_{1},x_{2})p(x_{4}\mid x_{2})\,.
$$

一般情况下，联合分布 $p(\pmb{x})=p(x_{1},\dots,x_{K})$ 给出为

$$
p(\pmb{x})=\prod_{k=1}^{K}p(x_{k}\,|\,\mathrm{\bfP a}_{k})\,,
$$

其中 $\mathtt{P a}_{k}$ 表示“$x_{k}$ 的父节点”。父节点是指有箭头指向 $x_{k}$ 的节点。

我们在本小节结束时给出硬币翻转实验的一个具体例子。考虑一个伯努利实验（示例 6.8），其中实验结果 $x$ 为“正面”的概率为

$$
p(x\,|\,\mu)=\mathrm{Ber}(\mu)\,.
$$

我们现在重复这个实验 $N$ 次，并观察结果 $x_{1},\dots,x_{N}$，从而我们得到联合分布

$$
p(x_{1},\ldots,x_{N}\,|\,\mu)=\prod_{n=1}^{N}p(x_{n}\,|\,\mu)\,.
$$

右侧的表达式是每个独立结果上的伯努利分布的乘积，因为实验是独立的。回想一下第 6.4.5 节，统计独立意味着分布可以因式分解。为了写出这种设置下的图模型，我们区分未观测/隐变量和观测变量。图形上，观测变量用阴影节点表示，因此我们得到图 8.10(a) 中的图模型。我们看到单个参数 $\mu$ 对所有 $x_{n}$ 都是相同的，$n=1,\ldots,N$，因为结果 $x_{n}$ 是同分布的。对于这种设置，更紧凑但等价的图模型如图 8.10(b) 所示，其中我们使用

![](images/9d8a9cea982f94cb42cdd6823b958f8c2873bdf703b38c233ff0f095ef6fe12d.jpg)  
图 8.10 重复伯努利实验的图模型。

**plate** 符号。plate（盒子）重复内部的一切（在这种情况下，重复观察 $x_{n}$） $N$ 次。因此，这两种图模型是等价的，但 plate 符号更紧凑。图模型立即允许我们在 $\mu$ 上放置超先验。**超先验** 是对第一层先验参数的第二层先验分布。图 8.10(c) 在隐变量 $\mu$ 上放置了一个 Beta$(\alpha,\beta)$ 先验。如果我们把 $\alpha$ 和 $\beta$ 当作确定性参数，即不是随机变量，我们就省略它周围的圆圈。

### 8.5.2 条件独立性和 d-分离

有向图模型允许我们仅通过观察图来找出联合分布的条件独立关系属性。一个称为 **d-分离** 的概念对此至关重要（Pearl, 1988）。

考虑一个一般的有向图，在这个图中，${\mathcal{A}}, {\mathcal{B}}, {\mathcal{C}}$ 是任意互不相交的节点集（它们的并集可能小于图中所有节点的集合）。我们希望确定特定的条件独立声明，“$\mathcal{A}$ 在给定 $\mathcal{C}$ 的条件下，是否条件独立于 $\mathcal{B}$”，记作

$$
{\mathcal{A}}\perp\!\perp{\mathcal{B}}\,\vert\,{\mathcal{C}}\,.
$$

是否由给定的有向无环图得出。为此，我们需要考虑从 $\mathcal{A}$ 中的任意节点到 $\mathcal{B}$ 中的任意节点的所有可能路径（忽略箭头的方向）。任何这样的路径如果包含以下任意一种情况的节点，则被认为是阻塞的：

- 路径上的箭头在该节点处以头对尾或尾对尾的方式相遇，并且该节点在集合 $\mathcal{C}$ 中。
- 箭头在该节点处以头对头的方式相遇，并且该节点及其后代均不在集合 $\mathcal{C}$ 中。

如果所有路径都被阻塞，则称 $\mathcal{A}$ 由 $\mathcal{C}$ **d-分离** 出 $\mathcal{B}$，并且图中所有变量的联合分布将满足

$$
{\mathcal{A}}\perp\!\perp{\mathcal{B}}\,|\,{\mathcal{C}}\,.
$$

$@2024$ M. P. Deisenroth, A. A. Faisal, C. S. Ong. 出版社：剑桥大学出版社（2020年）。

![](images/013412b4116df83db6e2a8cb721f21d169fcb5ff5b954cb98fa2b7f514c4799b.jpg)  
图 8.12 三种类型的图形模型：(a) 有向图形模型（贝叶斯网络）；(b) 无向图形模型（马尔可夫随机场）；(c) 因子图。

### 示例 8.9（条件独立）

图 8.11 d-分离示例。

![](images/b8e4342b68d9d0a97ac5de4b2a8792c6938a7b62f127b43ddca027f0808e5563.jpg)

考虑图 8.11 中的图形模型。直观检查给出

$$
\begin{aligned}
& b \perp d \mid a, c \\
& a \perp c \mid b \\
& b \perp d \mid c \\
& a \perp c \mid b, e
\end{aligned}
$$

有向图模型允许概率模型的紧凑表示，我们在第 9、10 和 11 章中会看到有向图模型的例子。这种表示法，加上条件独立的概念，使我们可以将相应的概率模型分解成更容易优化的表达式。

概率模型的图形表示使我们能够直观地看到我们在模型结构上所做的设计选择的影响。我们经常需要对模型的结构做出高层次的假设。这些建模假设（超参数）会影响预测性能，但不能直接使用我们迄今为止所见过的方法进行选择。我们将在第 8.6 节讨论选择结构的不同方法。

### 8.5.3 进一步阅读

概率图形模型的介绍可以在 Bishop (2006, 第 8 章) 中找到，关于不同应用和相应算法影响的详细描述可以在 Koller 和 Friedman (2009) 的书中找到。概率图形模型主要有三种类型：

- **有向图形模型**（贝叶斯网络）；参见图 8.12(a)
- **无向图形模型**（马尔可夫随机场）；参见图 8.12(b)
- **因子图**；参见图 8.12(c)

图形模型允许基于图的算法进行推理和学习，例如通过局部消息传递。其应用范围从在线游戏中的排名（Herbrich 等人，2007）、计算机视觉（例如图像分割、语义标注、图像去噪、图像恢复（Kittler 和 Föglein，1984；Sucar 和 Gillies，1994；Shotton 等人，2006；Szeliski 等人，2008））到编码理论（McEliece 等人，1998）、求解线性方程组（Shental 等人，2008）以及信号处理中的迭代贝叶斯状态估计（Bickson 等人，2007；Deisenroth 和 Mohamed，2012）。

有向图形模型：贝叶斯网络  
无向图形模型：马尔可夫随机场  
因子图

特别重要但在本书中未讨论的一个实际应用主题是结构化预测（Bakir 等人，2007；Nowozin 等人，2014），它允许机器学习模型处理结构化的预测，例如序列、树和图。神经网络模型的流行使得可以使用更灵活的概率模型，从而导致许多有用的结构化模型应用（Goodfellow 等人，2016，第 16 章）。近年来，由于因果推断的应用（Pearl, 2009; Imbens 和 Rubin, 2015; Peters 等人，2017; Rosenbaum, 2017），人们对图形模型的兴趣重新高涨。

## 8.6 模型选择

在机器学习中，我们经常需要做出高层建模决策，这些决策会严重影响模型的性能。我们所做的选择（例如，似然函数的形式）会影响模型中自由参数的数量和类型，从而影响模型的灵活性和表达能力。更复杂的模型在某种程度上更加灵活，因为它们可以用来描述更多的数据集。例如，一次多项式（直线 $y=a_{0}+a_{1}x$）只能用来描述输入 $x$ 和观测值 $y$ 之间的线性关系。二次多项式不仅可以描述线性关系，还可以描述二次关系。
![](images/740cf122adb4c8dbff8dfc9465842a8c469ec0771bbe0eac74c79f5a5550e76d.jpg)
现在人们可能会认为，非常灵活的模型通常比简单的模型更好，因为它们更具表达能力。但实际问题在于，在训练时我们只能使用训练集来评估模型的性能并学习其参数。然而，训练集上的表现并不是我们真正关心的。在第8.3节中，我们已经看到最大似然估计可能导致过拟合，特别是在训练数据集较小时。理想情况下，我们的模型（也）应该在测试集上表现良好（而测试集在训练时是不可用的）。因此，我们需要一些机制来评估模型对未见过的测试数据的泛化能力。**模型选择**正是为此问题设计的。

### 8.6.1 嵌套交叉验证

嵌套交叉验证  
测试集 验证集  

标准误差定义为 $\frac{\sigma}{\sqrt{K}}$ ，其中 $K$ 是实验次数，$\sigma$ 是每个实验风险的标准差。

我们已经看到了一种方法（第8.2.4节中的交叉验证）可以用于模型选择。回想一下，交叉验证通过反复将数据集拆分为训练集和验证集来估算泛化误差。我们可以再次应用这个想法，即对于每次拆分，我们都可以执行另一轮交叉验证。这有时被称为**嵌套交叉验证**；见图8.13。
![](images/d0c80aea9faef83a814f1d19860d013956a275d2ed396f7d5c467e14e8866845.jpg)
内层用于估算特定模型或超参数在内部验证集上的性能。外层用于估算由内层循环选出的最佳模型的泛化性能。我们可以在内层测试不同的模型和超参数选择。为了区分这两个层次，用于估算泛化性能的集合通常称为**测试集**，而用于选择最佳模型的集合称为**验证集**。内层通过使用验证集上的经验误差来近似给定模型的泛化误差期望值（8.39），即：

$$
\mathbb{E}_{\mathcal{V}}[\mathbf{R}(\mathcal{V}\,|\,M)]\approx\frac{1}{K}\sum_{k=1}^{K}\mathbf{R}(\mathcal{V}^{(k)}\,|\,M)\,,
$$

其中 ${\bf R}(\mathcal{V}\,|\,M)$ 是验证集 $\mathcal{V}$ 上模型 $M$ 的经验风险（例如，均方根误差）。我们对所有模型重复此过程，并选择表现最好的模型。请注意，交叉验证不仅给出了预期的泛化误差，我们还可以获得高阶统计量，例如标准误差，一个关于估计平均值不确定性的衡量指标。一旦选择了模型，我们就可以在测试集上评估最终性能。

### 8.6.2 贝叶斯模型选择

有许多模型选择的方法，其中一些方法将在本节中介绍。一般来说，它们都试图在模型复杂性和数据拟合之间取得平衡。我们假设简单的模型比复杂的模型更容易过拟合，因此模型选择的目标是找到一个足够简单且能合理解释数据的模型。这一概念也被称为**奥卡姆剃刀原理**。

图8.14 贝叶斯推断体现了奥卡姆剃刀原理。横轴表示所有可能数据集的空间 $\mathcal{D}$。证据（纵轴）评估模型预测可用数据的能力。由于 $p(\mathcal{D}\mid M_{i})$ 需要积分到 1，我们应该选择具有最大证据的模型。改编自 MacKay (2003)。

奥卡姆剃刀原理

备注。 如果我们将模型选择视为假设检验问题，我们正在寻找与数据一致的最简单的假设（Mur- phy, 2012）。$\diamondsuit$

有人可能会考虑在模型上放置一个先验，使简单的模型更受青睐。然而，这并非必要。一个“自动的奥卡姆剃刀”可以通过贝叶斯概率的应用定量体现出来（Smith and Spiegelhalter, 1980; Jefferys and Berger, 1992; MacKay, 1992）。图8.14，改编自MacKay (2003)，给我们提供了基本的直觉，为什么复杂的、表达能力强的模型可能不会成为建模给定数据集 $\mathcal{D}$ 的最佳选择。让我们把横轴看作所有可能数据集的空间 D。如果我们对模型 $M_{i}$ 在给定数据 D 后的后验概率 $p(M_{i}\,|\,\mathcal{D})$ 感兴趣，我们可以应用贝叶斯定理。假设对所有模型的先验 $p(M)$ 是均匀分布的，贝叶斯定理根据模型预测已发生数据的程度奖励模型。给定模型 $M_{i}$ 的数据预测 $p(\mathcal{D}\mid M_{i})$ 称为 $M_{i}$ 的**证据**。一个简单的模型 $M_{1}$ 只能预测少数几个数据集，这由 $p(\mathcal{D}\,|\,M_{1})$ 表示。一个更强大的模型 $M_{2}$，例如拥有比 $M_{1}$ 更多自由参数的模型，能够预测更多种类的数据集。这意味着 $M_{2}$ 并不能像 $M_{1}$ 那样很好地预测区域 C 中的数据集。如果两个模型被赋予相同的先验概率，那么当数据集落入区域 C 时，较弱的模型 $M_{1}$ 是更有可能的模型。

在本章早期，我们论证了模型需要能够解释数据，即应该有一种从给定模型生成数据的方法。此外，如果模型已经适当地从数据中学习，那么我们期望生成的数据应与经验数据相似。为此，将模型选择表述为层次推理问题是有帮助的，这允许我们计算模型的后验分布。
![](images/8dd7c33ad5ed27aaa3d6c102c0942075aeb7aad107c88c422ce5a479e8a30016.jpg)
贝叶斯模型选择生成过程 图8.15 贝叶斯模型选择中的层次生成过程插图。我们在模型集上放置一个先验 $p(M)$。对于每个模型，有一个对应的模型参数分布 $p(\pmb\theta\mid M)$，用于生成数据 $\mathcal{D}$。

模型证据 边缘似然

让我们覆盖有限数量的模型 $M=\{M_{1},.\,.\,.\,,M_{K}\}$，其中每个模型 $M_{k}$ 拥有参数 $\pmb{\theta}_{k}$。在**贝叶斯模型选择**中，我们在模型集中放置一个先验 $p(M)$。允许我们从该模型生成数据的相应**生成过程**是：

$$
\begin{array}{r l}&{M_{k}\sim p(\boldsymbol{M})}\\ &{\pmb{\theta}_{k}\sim p(\pmb{\theta}\,|\,M_{k})}\\ &{\quad\mathcal{D}\sim p(\mathcal{D}\,|\,\pmb{\theta}_{k})}\end{array}
$$

并如图8.15所示。给定训练集 $\mathcal{D}$，我们应用贝叶斯定理并计算模型的后验分布：

$$
p(M_{k}\,|\,\mathcal{D})\propto p(M_{k})p(\mathcal{D}\,|\,M_{k})\,.
$$

注意，这个后验不再依赖于模型参数 $\pmb{\theta}_{k}$，因为在贝叶斯设定中它们已经被积分掉了，因为

$$
p(\mathcal{D}\,|\,M_{k})=\int p(\mathcal{D}\,|\,\pmb{\theta}_{k})p(\pmb{\theta}_{k}\,|\,M_{k})d\pmb{\theta}_{k}\,,
$$

其中 $p(\pmb{\theta}_{k}\mid M_{k})$ 是模型参数 $\pmb{\theta}_{k}$ 的先验分布。项（8.44）称为**模型证据**或**边缘似然**。从（8.43）中的后验，我们确定最大后验估计：

$$
M^{*}=\arg\operatorname*{max}_{M_{k}}p(M_{k}\,|\,\mathcal{D})\,.
$$

假设一个均匀先验 $\begin{array}{r}{p(M_{k})=\frac{1}{K}}\end{array}$，它给每个模型相等的（先验）概率，确定模型的最大后验估计相当于选择最大化模型证据（8.44）的模型。

备注 （似然与边缘似然）。 似然和边缘似然（证据）之间有一些重要的区别：虽然似然是容易过拟合的，边缘似然通常不会，因为模型参数已被积分掉（即我们不再需要拟合参数）。此外，边缘似然自动体现了模型复杂性和数据拟合之间的权衡（奥卡姆剃刀原理）。$\diamondsuit$

### 8.6.3 模型比较的贝叶斯因子

考虑比较两个概率模型 $M_{1},M_{2}$，给定一个数据集 $\mathcal{D}$。如果我们计算后验 $p(M_{1}\,|\,\mathcal{D})$ 和 $p(M_{2}\,|\,\mathcal{D})$，我们可以计算后验比：

$$
\underbrace{p(M_{1}\,|\,\mathcal{D})}_{\mathrm{后验观察}}=\frac{\frac{p(\mathcal{D}\,|\,M_{1})p(M_{1})}{p(\mathcal{D})}}{\frac{p(\mathcal{D}\,|\,M_{2})p(M_{2})}{p(\mathcal{D})}}=\underbrace{\frac{p(M_{1})}{p(M_{2})}}_{\mathrm{先验观察}}\underbrace{\frac{p(\mathcal{D}\,|\,M_{1})}{p(\mathcal{D}\,|\,M_{2})}}_{\mathrm{贝叶斯因子}}。
$$

后验比也称为**后验几率**。等式右侧的第一个分数，即**先验几率**，衡量了我们的先验（初始）信念在多大程度上倾向于 $M_{1}$ 而不是 $M_{2}$。边缘似然比（等式右侧的第二个分数）称为**贝叶斯因子**，衡量了数据 $\mathcal{D}$ 被模型 $M_{1}$ 相比 $M_{2}$预测的程度。

后验几率 先验几率  

贝叶斯因子  

备注。 **杰弗里斯-林德利悖论**指出，“贝叶斯因子总是倾向于选择更简单的模型，因为在一个具有扩散先验的复杂模型下，数据的概率会非常小”（Murphy, 2012）。这里的扩散先验是指不偏向特定模型的先验，即在这种先验下，许多模型都是先验合理的。$\diamondsuit$

如果我们对模型选择一个均匀先验，等式（8.46）中的先验几率项为 1，即后验几率是边缘似然比（贝叶斯因子）

$$
\frac{p(\mathcal{D}\,|\,M_{1})}{p(\mathcal{D}\,|\,M_{2})}\,。
$$

如果贝叶斯因子大于 1，我们选择模型 $M_{1}$，否则选择模型 $M_{2}$。类似于频率统计学，对于结果的“显著性”，有一套关于比率大小的指南（Jeffreys, 1961）。

备注 （计算边缘似然）。 边缘似然在模型选择中起着重要作用：我们需要计算贝叶斯因子（8.46）和模型的后验分布（8.43）。

不幸的是，计算边缘似然要求我们解决一个积分（8.44）。这种积分通常是解析不可解的，我们必须求助于近似技术，例如数值积分（Stoer and Burlirsch, 2002）、使用蒙特卡洛的随机近似（Murphy, 2012），或贝叶斯蒙特卡洛技术（O’Hagan, 1991; Rasmussen and Ghahramani, 2003）。

然而，在某些特殊情况下，我们可以解决这个问题。在第6.6.1节中，我们讨论了共轭模型。如果我们选择一个共轭参数先验 $p(\pmb\theta)$，我们可以计算边缘似然的封闭形式。在第9章中，我们将在这个背景下讨论线性回归的具体情况。$\diamondsuit$

在本章中，我们简要介绍了机器学习的基本概念。在本书的其余部分，我们将看到在第8.2、8.3和8.4节中讨论的三种不同学习方式如何应用于机器学习的四大支柱（回归、降维、密度估计和分类）。

### 8.6.4 进一步阅读

在本节开始时我们提到，高层次的建模选择会影响模型的性能。以下是一些例子：

在参数化模型中，参数的数量通常与模型类的复杂度相关。

赤池信息准则

回归设置中多项式的次数 混合模型中的组件数量 （深度）神经网络的网络架构 支持向量机中的核类型 主成分分析（PCA）中的潜在空间维度 优化算法中的学习率（调度）

Rasmussen 和 Ghahramani (2001) 表明，自动奥卡姆剃刀并不一定会惩罚模型中的参数数量，但在函数复杂度方面是活跃的。他们还表明，自动奥卡姆剃刀对于具有许多参数的贝叶斯非参数模型（例如高斯过程）同样适用。

如果我们关注最大似然估计，存在一些用于模型选择的经验法则来抑制过拟合。这些被称为信息准则，我们选择具有最大值的模型。赤池信息准则 (AIC) (Akaike, 1974)

$$
\log p(\pmb{x}\,|\,\pmb{\theta})-M
$$

通过添加一个惩罚项来修正最大似然估计器的偏差，以补偿具有大量参数的更复杂模型的过拟合。此处，$M$ 是模型参数的数量。AIC 估计了给定模型所丢失的相对信息量。

贝叶斯信息准则

贝叶斯信息准则 (BIC) (Schwarz, 1978)

$$
\log p(\pmb{x})=\log\int p(\pmb{x}\,|\,\pmb{\theta})p(\pmb{\theta})\mathrm{d}\pmb{\theta}\approx\log p(\pmb{x}\,|\,\pmb{\theta})-\frac{1}{2}M\log N
$$

可用于指数族分布。此处，$N$ 是数据点的数量，$M$ 是参数的数量。BIC 对模型复杂度的惩罚比 AIC 更重。